{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "146151fc-b814-4fb0-ac78-7f3210e8425e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy as sci\n",
    "import glob\n",
    "import mne\n",
    "from autoreject import AutoReject\n",
    "from mne.preprocessing import ICA\n",
    "from mne_icalabel import label_components\n",
    "from autoreject import get_rejection_threshold\n",
    "from utills import cal_foof\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set figure resolution\n",
    "plt.rcParams['figure.dpi'] = 600\n",
    "plt.rcParams['savefig.dpi'] = 600\n",
    "\n",
    "# Paths\n",
    "data_path = '/home/hno/datasets/update_for_hamzeh/Python/IOWA_DATA/IOWA_Processing/Public_Datasets/Raw_data/'\n",
    "save_root = '/home/hno/datasets/update_for_hamzeh/Python/IOWA_DATA/IOWA_Processing/results/'\n",
    "# Groups\n",
    "groups = ['pd', 'hc']\n",
    "\n",
    "# AutoReject initialization\n",
    "ar = AutoReject(cv=3, n_interpolate=[1, 4, 8, 16], consensus=[0.5, 1], random_state=313, n_jobs=-1,\n",
    "                thresh_method='bayesian_optimization', verbose=False)\n",
    "\n",
    "# Function for processing each group (Parkinson or Healthy)\n",
    "def process_group(group, sbj_files, save_root):\n",
    "    ica_rejected = dict()\n",
    "    failed_subj = dict()\n",
    "    bad_subj = dict()\n",
    "    group_result = dict()\n",
    "\n",
    "    for fmin, fmax in freqs:\n",
    "        f_range = [fmin, fmax]\n",
    "        save_fooof = os.path.join(save_root, f'Range_{fmin}-{fmax}_Hz')\n",
    "        os.makedirs(save_fooof, exist_ok=True)\n",
    "        print(f'{group.capitalize()} Group: Range {f_range} Started ....')\n",
    "\n",
    "        for subj in sbj_files:\n",
    "            name = subj.split('_Rest/')[-1].split('.vhdr')[0]\n",
    "            raw = mne.io.read_raw_brainvision(subj, preload=True, verbose=False)\n",
    "\n",
    "            # Apply filters and other preprocessing steps\n",
    "            filtered = preprocess_data(raw)\n",
    "\n",
    "            # ICA decomposition\n",
    "            ica = ICA(n_components=len(filtered.ch_names) - 1, max_iter=\"auto\", method=\"infomax\", random_state=313)\n",
    "            ica.fit(filtered.copy(), verbose=False)\n",
    "\n",
    "            # Labeling ICA components and rejecting bad components\n",
    "            exclude_idx = label_and_reject_ica(ica, filtered)\n",
    "\n",
    "            if len(np.unique(exclude_idx)) == len(ica.labels_) or len(np.unique(exclude_idx)) > 0.8 * len(ica.labels_):\n",
    "                print(f'All components rejected for Subj {name}')\n",
    "                bad_subj[group] = subj\n",
    "                continue\n",
    "\n",
    "            # Apply ICA rejection\n",
    "            raw_ica = ica.apply(filtered.copy(), exclude=np.unique(exclude_idx), verbose=False)\n",
    "            epochs_ar = create_epochs(raw_ica)\n",
    "            epochs_ar.save(os.path.join(save_fooof, f'{name}_epo.fif'), overwrite=True)\n",
    "\n",
    "            # Store results\n",
    "            group_result[name] = cal_foof(epochs_ar, f_range=f_range, low_freq_to_del=False, high_freq_to_del=False, remove_line_noise=False)\n",
    "\n",
    "        # Saving results\n",
    "        save_results(save_fooof, group, ica_rejected, failed_subj, bad_subj, group_result)\n",
    "\n",
    "# Preprocessing data\n",
    "def preprocess_data(raw):\n",
    "    filtered = raw.copy().pick(picks=\"eeg\").filter(l_freq=1, h_freq=100, picks=None, filter_length='auto',\n",
    "                                                   l_trans_bandwidth='auto', h_trans_bandwidth='auto', n_jobs=-1,\n",
    "                                                   method='iir', iir_params=None, phase='zero', pad='reflect_limited', verbose=False)\n",
    "    montage = filtered.get_montage()\n",
    "    filtered.set_montage(montage, match_case=False)\n",
    "    filtered.apply_function(sci.signal.detrend, type='linear')\n",
    "    filtered.set_eeg_reference(ref_channels='average', verbose=False)\n",
    "    return filtered\n",
    "\n",
    "# Labeling and rejecting ICA components\n",
    "def label_and_reject_ica(ica, filtered):\n",
    "    try:\n",
    "        ica_labels = label_components(filtered, ica, method='iclabel')\n",
    "        labels = ica_labels[\"labels\"]\n",
    "        exclude_idx = [idx for idx, label in enumerate(labels) if label not in [\"brain\"]]\n",
    "        # if label in [\"brain\"] and ica_labels['y_pred_proba'][idx] < 0.7: # optional\n",
    "            #exclude_idx.append(idx)\n",
    "    except:\n",
    "        print(f\"ICA labeling failed\")\n",
    "        return []\n",
    "\n",
    "    return exclude_idx\n",
    "\n",
    "# Creating epochs\n",
    "def create_epochs(raw_ica):\n",
    "    epochs = mne.make_fixed_length_epochs(raw_ica, duration=1, overlap=0, preload=True, verbose=False)\n",
    "    epochs.apply_function(sci.signal.detrend, type='linear')\n",
    "    reject_criteria = get_rejection_threshold(epochs)\n",
    "    epochs.drop_bad(reject=reject_criteria, verbose=False)\n",
    "    ar.fit(epochs)\n",
    "    epochs_ar, rejected_log = ar.fit_transform(epochs, return_log=True)\n",
    "    epochs_ar.pick(['eeg'])\n",
    "    return epochs_ar\n",
    "\n",
    "# Saving results\n",
    "def save_results(save_fooof, group, ica_rejected, failed_subj, bad_subj, group_result):\n",
    "    with open(os.path.join(save_fooof, f'failed_subj.pkl'), 'wb') as file:\n",
    "        pickle.dump(failed_subj[group], file)\n",
    "\n",
    "    with open(os.path.join(save_fooof, 'bad_subj.pkl'), 'wb') as file:\n",
    "        pickle.dump(bad_subj[group], file)\n",
    "\n",
    "    with open(os.path.join(save_fooof, f'{group.capitalize()}_rejected_ICs.pkl'), 'wb') as file:\n",
    "        pickle.dump(ica_rejected[group], file)\n",
    "\n",
    "    with open(os.path.join(save_fooof, f'{group}.pkl'), 'wb') as file:\n",
    "        pickle.dump(group_result, file)\n",
    "\n",
    "# Get subject files\n",
    "files = glob.glob(os.path.join(data_path, '**/*.vhdr'), recursive=True)\n",
    "sbj_files = sorted([file for file in files if '.vhdr' in file])\n",
    "parkinson = [file for file in sbj_files if 'PD' in file]\n",
    "healthy = [file for file in sbj_files if 'Con' in file]\n",
    "\n",
    "# Process both groups\n",
    "process_group('pd', parkinson, save_root)\n",
    "process_group('hc', healthy, save_root)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define conditions and file paths\n",
    "condition = ['PD vs HC', 'Parkinson', 'Control']\n",
    "save_root = '/path/to/your/dataset/IOWA_Processing'\n",
    "data_path = '/path/to/your/dataset/IOWA_Processing/results'\n",
    "\n",
    "# Frequency ranges for analysis\n",
    "freqs = [\n",
    "    [1, 20], [1, 30], [1, 40], [1, 50], [1, 60], [1, 70], [1, 80], [1, 90], [3, 20], [3, 30], [3, 40], [3, 50], [3, 60], [3, 70], [3, 80], [3, 90]\n",
    "]\n",
    "\n",
    "# Loop through the frequency ranges for analysis\n",
    "for freq in freqs:\n",
    "    fmin, fmax = freq\n",
    "    f_range = [fmin, fmax]\n",
    "\n",
    "    # Directory to save the processed data for this frequency range\n",
    "    save_fooof = os.path.join(save_root, f'Range_{fmin}-{fmax}_Hz')\n",
    "    os.makedirs(save_fooof, exist_ok=True)\n",
    "    print(f'Starting analysis for frequency range {f_range} Hz...')\n",
    "\n",
    "    # Load Parkinson's and Control data\n",
    "    with open(os.path.join(data_path, 'parkinson.pkl'), 'rb') as f:\n",
    "        parkinson_data = pickle.load(f)\n",
    "\n",
    "    with open(os.path.join(data_path, 'healthy.pkl'), 'rb') as f:\n",
    "        control_data = pickle.load(f)\n",
    "\n",
    "    # Calculate accuracy for the Control group\n",
    "    acc_control = [1 - control_data[name]['AllScalp'].error_ for name in control_data]\n",
    "\n",
    "    # Calculate accuracy for the Parkinson's group\n",
    "    acc_parkinson = [1 - parkinson_data[name]['AllScalp'].error_ for name in parkinson_data]\n",
    "\n",
    "    # Calculate Z-scores for outlier detection\n",
    "    z_score_PD = [abs((x - np.mean(acc_parkinson)) / np.std(acc_parkinson)) for x in acc_parkinson]\n",
    "    z_score_CT = [abs((x - np.mean(acc_control)) / np.std(acc_control)) for x in acc_control]\n",
    "\n",
    "    # Identify outliers with Z-score > 2\n",
    "    bad_index_PD = [x for x, z in enumerate(z_score_PD) if z > 2]\n",
    "    bad_index_CT = [x for x, z in enumerate(z_score_CT) if z > 2]\n",
    "\n",
    "    # Remove outliers from both Parkinson's and Control data\n",
    "    parkinson_data_cleaned = {k: v for i, (k, v) in enumerate(parkinson_data.items()) if i not in bad_index_PD}\n",
    "    control_data_cleaned = {k: v for i, (k, v) in enumerate(control_data.items()) if i not in bad_index_CT}\n",
    "\n",
    "    # Save cleaned data\n",
    "    with open(os.path.join(save_fooof, 'Healthy_group.pkl'), 'wb') as f:\n",
    "        pickle.dump(control_data_cleaned, f)\n",
    "\n",
    "    with open(os.path.join(save_fooof, 'Parkinson_group.pkl'), 'wb') as f:\n",
    "        pickle.dump(parkinson_data_cleaned, f)\n",
    "\n",
    "    # Generate signal plots and extract frequency features\n",
    "    results = signal_plot(parkinson_data_cleaned, control_data_cleaned, save_fooof, condition=['', '', ''])\n",
    "    peak_index = get_area(results, f_range, save_root=save_fooof, srate=500)\n",
    "\n",
    "    # Define regions and features of interest\n",
    "    regions = ['Frontal', 'Central', 'Occipital', 'Left', 'Right', 'AllScalp']\n",
    "    features = ['ID', 'acc', 'exp', 'offs', 'alpha-CF', 'alpha-peak', 'beta-CF', 'beta-peak']\n",
    "\n",
    "    brain_features = {'PD': {region: {feature: [] for feature in features} for region in regions},\n",
    "                      'CT': {region: {feature: [] for feature in features} for region in regions}}\n",
    "\n",
    "    # Populate brain features for Parkinson's group\n",
    "    for region in regions:\n",
    "        for name in parkinson_data_cleaned:\n",
    "            brain_features['PD'][region]['ID'].append(name)\n",
    "            brain_features['PD'][region]['exp'].append(np.round(parkinson_data_cleaned[name][region].get_params('aperiodic_params')[1], 4))\n",
    "            brain_features['PD'][region]['offs'].append(np.round(parkinson_data_cleaned[name][region].get_params('aperiodic_params')[0], 4))\n",
    "            brain_features['PD'][region]['acc'].append(np.round(1 - parkinson_data_cleaned[name][region].error_, 4))\n",
    "\n",
    "        brain_features['PD'][region]['alpha-CF'] = list(peak_index['parkinson'][region]['alpha']['CF'])\n",
    "        brain_features['PD'][region]['alpha-peak'] = list(peak_index['parkinson'][region]['alpha']['peak'])\n",
    "        brain_features['PD'][region]['beta-CF'] = list(peak_index['parkinson'][region]['beta']['CF'])\n",
    "        brain_features['PD'][region]['beta-peak'] = list(peak_index['parkinson'][region]['beta']['peak'])\n",
    "\n",
    "    # Populate brain features for Control group\n",
    "    for region in regions:\n",
    "        for name in control_data_cleaned:\n",
    "            brain_features['CT'][region]['ID'].append(name)\n",
    "            brain_features['CT'][region]['exp'].append(np.round(control_data_cleaned[name][region].get_params('aperiodic_params')[1], 4))\n",
    "            brain_features['CT'][region]['offs'].append(np.round(control_data_cleaned[name][region].get_params('aperiodic_params')[0], 4))\n",
    "            brain_features['CT'][region]['acc'].append(np.round(1 - control_data_cleaned[name][region].error_, 4))\n",
    "\n",
    "        brain_features['CT'][region]['alpha-CF'] = list(peak_index['healthy'][region]['alpha']['CF'])\n",
    "        brain_features['CT'][region]['alpha-peak'] = list(peak_index['healthy'][region]['alpha']['peak'])\n",
    "        brain_features['CT'][region]['beta-CF'] = list(peak_index['healthy'][region]['beta']['CF'])\n",
    "        brain_features['CT'][region]['beta-peak'] = list(peak_index['healthy'][region]['beta']['peak'])\n",
    "\n",
    "    # Create a DataFrame from the extracted features\n",
    "    rows = []\n",
    "    for group, regions in brain_features.items():\n",
    "        for region, features in regions.items():\n",
    "            length = len(parkinson_data_cleaned) if group == 'PD' else len(control_data_cleaned)\n",
    "            for i in range(length):\n",
    "                row = {\n",
    "                    'ID': features['ID'][i],\n",
    "                    'Group': group,\n",
    "                    'Region': region,\n",
    "                    'acc': features['acc'][i],\n",
    "                    'exp': features['exp'][i],\n",
    "                    'offs': features['offs'][i],\n",
    "                    'alpha-CF': np.round(features['alpha-CF'][i], 4),\n",
    "                    'alpha-peak': features['alpha-peak'][i],\n",
    "                    'beta-CF': np.round(features['beta-CF'][i], 4),\n",
    "                    'beta-peak': features['beta-peak'][i]\n",
    "                }\n",
    "                rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=['ID', 'Group', 'Region', 'acc', 'exp', 'offs', 'alpha-CF', 'alpha-peak', 'beta-CF', 'beta-peak'])\n",
    "\n",
    "    # Save the DataFrame as CSV\n",
    "    df.to_csv(os.path.join(save_fooof, 'data.csv'), index=False)\n",
    "\n",
    "    print(f'Analysis for frequency range {f_range} Hz completed.')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
